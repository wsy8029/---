{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "● 관련 라이브러리 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "● 라벨이름, 디렉토리 위치 등 초기 변수 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_src_list = []\n",
    "\n",
    "# 학습 이미지 라벨링 \n",
    "class_names = ['traffic_green','traffic_red']\n",
    "data_directory = '../data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "● data 폴더안에 학습하고자 하는 이미지를 학습 가능한 형태로 변형 및 학습용 데이터와 테스트용 데이터를 분리하는 전처리 부분."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133, 24, 32, 3)\n",
      "(39, 24, 32, 3)\n",
      "(18, 24, 32, 3)\n",
      "(133, 2)\n",
      "(39, 2)\n",
      "(18, 2)\n"
     ]
    }
   ],
   "source": [
    "# train data list, label list 생성\n",
    "X_ = []\n",
    "y_ = []\n",
    "\n",
    "# 데이터별 path 설정\n",
    "for label_idx, target in enumerate(class_names):\n",
    "\n",
    "    target_directory = data_directory + '/' + target\n",
    "    \n",
    "    lst = os.listdir(data_directory)\n",
    "    if '.DS_Store' in lst:\n",
    "        lst.remove('.DS_Store')\n",
    "\n",
    "    if '.ipynb_checkpoints' in lst:\n",
    "        lst.remove('.ipynb_checkpoints')\n",
    "    \n",
    "    label_cnt = len(lst)\n",
    "    \n",
    "    test_cnt = 0\n",
    "\n",
    "    for each_file in os.listdir(target_directory):\n",
    "        test_cnt += 1\n",
    "\n",
    "        # 각 train image 파일 path 설정\n",
    "        file_path = '{}/{}/{}'.format(data_directory, target, each_file)\n",
    "\n",
    "        # train image file load\n",
    "        tmp_img = image.load_img(file_path, target_size=(24, 32))\n",
    "        tmp_img = image.img_to_array(tmp_img)\n",
    "\n",
    "        # Width x Height x RGB 에 해당하는 3차원 numpy 배열을 flattening\n",
    "        X_.append(tmp_img)\n",
    "\n",
    "        # one-hot encoding(labeling)\n",
    "        temp_label = np.repeat(0, label_cnt)\n",
    "        temp_label[label_idx] = 1\n",
    "        y_.append(temp_label)\n",
    "\n",
    "X_ = np.array(X_).astype(np.float16)\n",
    "y_ = np.array(y_).astype(np.float16)\n",
    "\n",
    "# train, valid ,test data 로 나누기 \n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X_, y_, test_size=0.3, random_state=100)\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_temp, y_temp, test_size=0.3, random_state=100)\n",
    "\n",
    "print(X_train.shape) # (현재 이미지 수, 이미지 높이크기, 이미지 폭, RGB(3))\n",
    "print(X_valid.shape) # (현재 이미지 수, 이미지 높이크기, 이미지 폭, RGB(3))\n",
    "print(X_test.shape)  \n",
    "print(y_train.shape) # (현재 이미지 수, 라벨 수)\n",
    "print(y_valid.shape) # (현재 이미지 수, 라벨 수)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "●Custom Neural Net 모델 형성 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델 구축 완료\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(\n",
    "    Conv2D(input_shape = (24, 32, 3), filters = 32, kernel_size = (3,3), strides = (3,3),\n",
    "           padding = 'same', activation = 'relu')\n",
    ")\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(\n",
    "    Conv2D(filters = 128, kernel_size = (3,3), strides = (1,1),\n",
    "           padding = 'same', activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(\n",
    "    Conv2D(filters = 128, kernel_size = (3,3), strides = (1,1),\n",
    "           padding = 'same', activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(2, activation = 'softmax'))\n",
    "\n",
    "print('모델 구축 완료')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "● 모델 학습 실행 파트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 옵티마이저 함수 준비\n",
    "opt = keras.optimizers.Adam(learning_rate = 0.001)\n",
    "# 모델 컴파일링 수행\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = opt, metrics = ['accuracy',])\n",
    "\n",
    "# 학습 진행\n",
    "hist = model.fit(X_train, y_train, validation_data = (X_valid, y_valid), epochs = 30, batch_size = 32)\n",
    "\n",
    "# 학습된 모델 저장 경로 설정 및 저장 함수\n",
    "model_path = '../model/' + 'model1.h5'\n",
    "model.save(model_path)\n",
    "\n",
    "print(\"모델 생성 및 저장 완료\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
